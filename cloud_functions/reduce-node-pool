from google.cloud import container_v1beta1
from prettytable import PrettyTable

import functions_framework
import time
import json
import os
import requests


project_id = os.environ.get("PROJECTID")
client = container_v1beta1.ClusterManagerClient()
table = PrettyTable()
skip_table = PrettyTable()

@functions_framework.http
def reduce_node_pool(request):
    try:
        skip_list = []
        if len(os.environ.get("SKIP_LIST")) > 0:
            skip_list = os.environ.get("SKIP_LIST").split(",")
        print("\n list of skipped vm's*******", skip_list)
        table.field_names = ["GKE Cluster Name"]
        skip_table.field_names = ["GKE Cluster Name"]
        request = container_v1beta1.ListClustersRequest(
            project_id=project_id,
            zone="-"
        )
        response = client.list_clusters(request=request)
        clusters = response.clusters
        print("Total clusters are ", len(clusters))
        for cluster in clusters:
            cluster_name = cluster.name
            try:
                if cluster_name != 'gogen' and cluster_name not in skip_list and cluster.current_node_count > 0:
                    print(f"{cluster_name} is qualified to reduce the node pool")
                    update_node_pool(cluster)
                    table.add_row([cluster.name])
                elif cluster_name in skip_list:
                    print(f"{cluster_name} is added to skip table")
                    skip_table.add_row([cluster_name])
            except Exception as e1:
                print(f"An error occured during {cluster_name} node pool update", e1)

    except Exception as e:
        print("an error occured", str(e))

    print(f"total rows {len(table.rows)}")
    send_slack_notification()
    return 'completed'


def send_slack_notification():
    URL = os.environ.get("SLACK_URL")
    HEADERS = {"content-type": "application/json"}
    message = ""
    if len(table.rows) > 0:
        message = "The following GKE instances node pool size reduced to zero as part of cost reduction:\n" + table.get_string()
    if len(skip_table.rows) > 0:
        message = message + "\n\n The following GKE instances are skipped as part of Skip List:\n" + skip_table.get_string()
    if len(message) == 0:
        message = "There is no GKE cluster is running with node pools. No  node pool reduction."
    slack_payload = json.dumps({"text": message})
    print(message)
    r = requests.post(URL, data=slack_payload, headers=HEADERS)
    print(r.status_code, r.reason)

def update_node_pool(cluster):
    node_pools = cluster.node_pools
    for node_pool in node_pools:
        print(f"{cluster.name}'s node pool size {len(node_pools)} and locations {node_pool.locations}")
        locations_size = len(node_pool.locations)
        location = ''
        if locations_size > 1:
            temp = node_pool.locations[0]
            location = temp[:-2]
        elif locations_size == 1:
            location = node_pool.locations[0]
        else:
            print(f"node pool locations are not found for {cluster.name}")
            location = ''

        print(f"{cluster.name}'s location is: {location}")
        if location != '':
            node_auto_scaling = container_v1beta1.NodePoolAutoscaling(
                enabled=False,
                max_node_count=0
            )
            update_object = container_v1beta1.ClusterUpdate(
                desired_node_pool_autoscaling=node_auto_scaling
            )
            update_request = container_v1beta1.UpdateClusterRequest(
                name=f"projects/{project_id}/locations/{location}/clusters/{cluster.name}/nodePools/{node_pool.name}",
                update=update_object
            )
            client.update_cluster(request=update_request)
            print(f"{cluster.name}'s updated auto scale")
            time.sleep(30)
            node_pool_request = container_v1beta1.SetNodePoolSizeRequest(
                name=f"projects/{project_id}/locations/{location}/clusters/{cluster.name}/nodePools/{node_pool.name}",
                node_count=0
            )
            client.set_node_pool_size(request=node_pool_request)
            print(f"{cluster.name}'s updated node pool size")
